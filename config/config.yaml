model:
  image_size: [224, 224]
  patch_size: 16
  d_model: 384 #768
  num_layers_encoder: 4 #12
  num_layers_decoder: 2 #4
  num_heads_encoder: 4 #8 #12
  num_heads_decoder: 2 #6 #8
  mask_ratio: 0.75
  n_channels: 4

training:
  batch_size: 8
  num_epochs: 1000
  learning_rate: 0.00003
  weight_decay: 0.0001
  alpha: 1.0
  beta: 1.0
  mask_ratio: 0.75

data:
  depth_model_checkpoint: /home/ndelafuente/VD-MAE/depth_anything_v2/checkpoints/depth_anything_v2_vitl.pth


